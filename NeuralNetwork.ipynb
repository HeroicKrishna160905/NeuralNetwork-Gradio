{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4711f734-6083-4ff5-871e-9efa3eb21baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chour\\envs\\tf311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.4266\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1059\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.0690\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0491\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0391\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0291\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0239\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0215\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0205\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0157\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1460\n",
      "Test accuracy: 0.9722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "The model predicts this digit as: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#pre-processing\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0   #normalize\n",
    "x_test = x_test.astype(\"float32\") / 255.0    \n",
    "y_train = to_categorical(y_train, 10)        \n",
    "y_test = to_categorical(y_test, 10)          \n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),       \n",
    "    Dense(128, activation='relu'),       \n",
    "    Dense(64, activation='relu'),         \n",
    "    Dense(10, activation='softmax')      \n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "#evaluatn\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "def predict_custom_image(image_path, invert_if_needed=True):\n",
    "  \n",
    "    if not os.path.isfile(image_path):\n",
    "        print(f\"Error: File '{image_path}' does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Loadimagin grayscale\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28, 28)) #resize\n",
    "    \n",
    "    if invert_if_needed:   #contratsconversn\n",
    "        mean_pixel = np.array(img).mean()\n",
    "        if mean_pixel > 127: \n",
    "            img = ImageOps.invert(img)\n",
    "            \n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    img_array = img_array.reshape(1, 28, 28)  # For Dense/Flatten input\n",
    "\n",
    "   \n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_digit = np.argmax(predictions)\n",
    "    print(f\"The model predicts this digit as: {predicted_digit}\")\n",
    "    return predicted_digit\n",
    "\n",
    "\n",
    "predict_custom_image('digit_28x28.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558e9202-6bcd-4759-950d-e79eb57c88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"digit9.png\").convert(\"L\")  # Convert to grayscale\n",
    "img = img.resize((28, 28))  # Resize to 28x28\n",
    "img.save(\"digit9_.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d53f80-02c5-4e24-bacc-ee8b74bc37a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "The model predicts this digit as: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_custom_image('digit9_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f553e48-25cd-46f4-9b04-f1f8d5b171dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"digit8.png\").convert(\"L\")  # Convert to grayscale\n",
    "img = img.resize((28, 28))  # Resize to 28x28\n",
    "img.save(\"digit8_.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9129791-2840-4476-b05b-1350f6624d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "The model predicts this digit as: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_custom_image('digit8_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdbb4fe3-338b-451b-bf61-6380d9aea7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"digit1.png\").convert(\"L\")  # Convert to grayscale\n",
    "img = img.resize((28, 28))  # Resize to 28x28\n",
    "img.save(\"digit1_.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b05a4132-9345-4266-a51c-d9f53f25f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "The model predicts this digit as: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_custom_image('digit1_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103f1d5c-ff3d-4c53-bc07-3f2e8a302c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digit.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd4aac-029c-48fb-b493-2e8b931975e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf311)",
   "language": "python",
   "name": "tf311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
